{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fa73775db80ea3",
   "metadata": {},
   "source": [
    "# Seminar 8: Concurrency Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6950608120bc1",
   "metadata": {},
   "source": [
    "## Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c64b2d38999f",
   "metadata": {},
   "source": [
    "### Basic Multithreading in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eda0384b28e93",
   "metadata": {},
   "source": [
    "![GIL](GIL-behaviour.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261be48ebddcacbd",
   "metadata": {},
   "source": [
    "Historically, Python has GIL, so only one thread can be executed at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af7b2cd75631e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:13:48.858246Z",
     "start_time": "2025-08-24T11:13:43.847287Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def simple_worker(time_wait_seconds: float) -> None:\n",
    "    print(f\"Thread {threading.current_thread().name} started. Sleeping for {time_wait_seconds:.3f} seconds\")\n",
    "    time.sleep(time_wait_seconds)\n",
    "    print(f\"Thread {threading.current_thread().name} finished. Exiting.\")\n",
    "\n",
    "\n",
    "thread1 = threading.Thread(target=simple_worker, args=(2,), name=\"Worker-1\")\n",
    "thread2 = threading.Thread(target=simple_worker, args=(5,), name=\"Worker-2\")\n",
    "\n",
    "print(\"Main: Starting threads\")\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "print(\"Main: Waiting for threads to finish...\")\n",
    "\n",
    "thread1.join()\n",
    "print(\"Main: Thread1 joined\")\n",
    "thread2.join()\n",
    "print(\"Main: Thread2 joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075fc21e2e6c26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:18:14.305858Z",
     "start_time": "2025-08-24T11:18:07.346143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sometimes due to mistakes/intentionally threads may never stop\n",
    "def never_ending_thread() -> None:\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        print(f\"Thread {threading.current_thread().name}: waiting\")\n",
    "\n",
    "\n",
    "thread = threading.Thread(target=never_ending_thread, name=\"Thread\")\n",
    "thread.start()\n",
    "print(\"Main: Thread started\")\n",
    "thread.join() # Will wait forever in the main thread\n",
    "print(\"Main: Thread joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348fc4c415dfd66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:19:44.388346Z",
     "start_time": "2025-08-24T11:19:39.383570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution: join with timeout\n",
    "def never_ending_thread() -> None:\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        print(f\"Thread {threading.current_thread().name}: waiting\")\n",
    "\n",
    "\n",
    "thread = threading.Thread(target=never_ending_thread, name=\"Thread\")\n",
    "thread.start()\n",
    "print(\"Main: Thread started\")\n",
    "thread.join(timeout=5) # Always whenever you can, put timeouts for safety.\n",
    "print(\"Main: Thread joined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430038ed8a5267a",
   "metadata": {},
   "source": [
    "Good use case for threading is the parallel downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c707fd221c144b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:29:04.429794Z",
     "start_time": "2025-08-24T11:28:13.283573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bad version (sequential download)\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "urls = [\n",
    "    'https://www.example.com',\n",
    "    'https://www.python.org',\n",
    "    'https://httpbin.org/get',\n",
    "    'https://www.github.com',\n",
    "    'https://www.stackoverflow.com'\n",
    "]\n",
    "\n",
    "def download_url(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Downloaded {url} with status {response.status_code}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Sequential execution\n",
    "for url in urls:\n",
    "    download_url(url)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(urls)} URLs in {duration:.2f} seconds sequentially.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda94455b2e8bb7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:29:12.670887Z",
     "start_time": "2025-08-24T11:29:04.431082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Good version (multithreading)\n",
    "\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "\n",
    "urls = [\n",
    "    'https://www.example.com',\n",
    "    'https://www.python.org',\n",
    "    'https://httpbin.org/get',\n",
    "    'https://www.github.com',\n",
    "    'https://www.stackoverflow.com'\n",
    "]\n",
    "\n",
    "def download_url(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Downloaded {url} with status {response.status_code}\")\n",
    "\n",
    "start_time = time.time()\n",
    "threads = []\n",
    "\n",
    "for url in urls:\n",
    "    thread = threading.Thread(target=download_url, args=(url,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(urls)} URLs in {duration:.2f} seconds with threading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae1aa75f81b795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:32:56.449662Z",
     "start_time": "2025-08-24T11:32:47.789579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bonus: cleaner example (spoiler: joblib)\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "urls = [\n",
    "    'https://www.example.com',\n",
    "    'https://www.python.org',\n",
    "    'https://httpbin.org/get',\n",
    "    'https://www.github.com',\n",
    "    'https://www.stackoverflow.com'\n",
    "]\n",
    "\n",
    "def download_url(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Downloaded {url} with status {response.status_code}\")\n",
    "    return response.status_code\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\", prefer=\"threads\")(\n",
    "    delayed(download_url)(url) for url in urls\n",
    ")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(urls)} URLs in {duration:.2f} seconds with joblib threading.\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a92aff4ba1df4",
   "metadata": {},
   "source": [
    "### Thread Synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9502d32edff04b4",
   "metadata": {},
   "source": [
    "The most challenging part of a concurrent program is when threads need to communicate with each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0308652487af1c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:54:11.391165Z",
     "start_time": "2025-08-24T11:54:11.384581Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "bank_account = 100\n",
    "print(f\"Initial balance: ${bank_account}\")\n",
    "\n",
    "def withdraw(amount):\n",
    "    global bank_account\n",
    "    \n",
    "    # Simulate some delay (e.g., checking the balance, processing the request)\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # --- CRITICAL SECTION START ---\n",
    "    # Check if there's enough money\n",
    "    if bank_account >= amount:\n",
    "        # Simulate some processing\n",
    "        time.sleep(0.001)\n",
    "        # Withdraw the money\n",
    "        bank_account -= amount\n",
    "        print(f\"{threading.current_thread().name} withdrew ${amount}. New balance: ${bank_account}\")\n",
    "    else:\n",
    "        print(f\"{threading.current_thread().name} failed to withdraw ${amount}. Insufficient funds.\")\n",
    "    # --- CRITICAL SECTION END ---\n",
    "\n",
    "husband = threading.Thread(target=withdraw, args=(90,), name='Husband')\n",
    "wife = threading.Thread(target=withdraw, args=(90,), name='Wife')\n",
    "\n",
    "husband.start()\n",
    "wife.start()\n",
    "\n",
    "husband.join()\n",
    "wife.join()\n",
    "\n",
    "print(f\"Final balance: ${bank_account}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4a57ba1c154be",
   "metadata": {},
   "source": [
    "What happened? Both threads checked if the bank has sufficient funds. But somehow it ended up with a negative balance.\n",
    "The behavior that we observe is called **a Race Condition**: multiple threads interact with shared resources at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865acd86dee66b50",
   "metadata": {},
   "source": [
    "The part of the code where such crazy stuff can happen, is called **a Critical Section**.\n",
    "We need to ensure that only one thread enters Critical Section at a time.\n",
    "The most straightforward way to do that is Mutex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665bd1e9442218a",
   "metadata": {},
   "source": [
    "![mutex](mutex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368f9a82fcbd578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:54:17.283593Z",
     "start_time": "2025-08-24T11:54:17.276404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "bank_account = 100\n",
    "print(f\"Initial balance: ${bank_account}\")\n",
    "\n",
    "account_lock = threading.Lock()\n",
    "\n",
    "def withdraw_safely(amount):\n",
    "    global bank_account\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # lock.acquire()\n",
    "    with account_lock:  # This automatically handles lock.acquire() and lock.release()\n",
    "        # --- CRITICAL SECTION START ---\n",
    "        print(f\"{threading.current_thread().name} is checking balance...\")\n",
    "        \n",
    "        if bank_account >= amount:\n",
    "            time.sleep(0.001)\n",
    "            bank_account -= amount\n",
    "            print(f\"{threading.current_thread().name} withdrew ${amount}. New balance: ${bank_account}\")\n",
    "        else:\n",
    "            print(f\"{threading.current_thread().name} failed to withdraw ${amount}. Insufficient funds.\")\n",
    "        # --- CRITICAL SECTION END ---\n",
    "    # lock.release()\n",
    "\n",
    "husband = threading.Thread(target=withdraw_safely, args=(90,), name='Husband')\n",
    "wife = threading.Thread(target=withdraw_safely, args=(90,), name='Wife')\n",
    "\n",
    "husband.start()\n",
    "wife.start()\n",
    "\n",
    "husband.join()\n",
    "wife.join()\n",
    "\n",
    "print(f\"Final balance: ${bank_account}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8ed9f643c7d52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T12:00:51.337644Z",
     "start_time": "2025-08-24T12:00:51.331568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaner example\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# It's usually better to wrap locks inside the services, so that the main code doesn't even see the inner lock.\n",
    "class BankAccount:\n",
    "    def __init__(self, amount: int):\n",
    "        self._amount = amount\n",
    "        self._lock = threading.Lock()\n",
    "    \n",
    "    def withdraw(self, request_amount: int) -> bool:\n",
    "        with self._lock:\n",
    "            if request_amount >= self._amount:\n",
    "                return False\n",
    "            self._amount -= request_amount\n",
    "            return True\n",
    "    \n",
    "    def get_balance(self) -> int:\n",
    "        return self._amount\n",
    "\n",
    "bank_account = BankAccount(amount=100)\n",
    "print(f\"Initial balance: ${bank_account.get_balance()}\")\n",
    "\n",
    "\n",
    "def withdraw_safely(amount):\n",
    "    global bank_account\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    success = bank_account.withdraw(amount)\n",
    "    if success:\n",
    "        print(f\"{threading.current_thread().name} withdrew ${amount}. New balance: ${bank_account.get_balance()}\")\n",
    "    else:\n",
    "        print(f\"{threading.current_thread().name} failed to withdraw ${amount}. Insufficient funds.\")\n",
    "    \n",
    "husband = threading.Thread(target=withdraw_safely, args=(90,), name='Husband')\n",
    "wife = threading.Thread(target=withdraw_safely, args=(90,), name='Wife')\n",
    "\n",
    "husband.start()\n",
    "wife.start()\n",
    "\n",
    "husband.join()\n",
    "wife.join()\n",
    "\n",
    "print(f\"Final balance: ${bank_account.get_balance()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d778ac822b572c",
   "metadata": {},
   "source": [
    "**The Dining Philosophers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30847009d098d072",
   "metadata": {},
   "source": [
    "![Dining-philosophers](dining-philosophers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d202ab04de94c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:23:15.892469Z",
     "start_time": "2025-08-25T07:23:10.378587Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "class Philosopher:\n",
    "    def __init__(self, index: int, left_fork: threading.Lock, right_fork: threading.Lock):\n",
    "        self.index = index\n",
    "        self._left_fork = left_fork\n",
    "        self._right_fork = right_fork\n",
    "    \n",
    "    def think(self):\n",
    "        print(f\"Philosopher {self.index} is thinking...\")\n",
    "        time.sleep(random.uniform(0.1, 0.5))\n",
    "    \n",
    "    def pick_left_fork(self):\n",
    "        print(f\"Philosopher {self.index} is hungry, trying to pick up left fork {self.index}\")\n",
    "        self._left_fork.acquire()\n",
    "        time.sleep(0.4)\n",
    "    \n",
    "    def pick_right_fork(self):\n",
    "        print(f\"Philosopher {self.index} is hungry, trying to pick up right fork {(self.index + 1) % PHILOSOPHERS_COUNT}\")\n",
    "        self._right_fork.acquire()\n",
    "        time.sleep(0.4)\n",
    "    \n",
    "    def eat(self):\n",
    "        print(f\"Philosopher {self.index} is EATING!\")\n",
    "        time.sleep(random.uniform(0.2, 0.4))\n",
    "    \n",
    "    def release_forks(self):\n",
    "        self._right_fork.release()\n",
    "        print(f\"Philosopher {self.index} put down right fork\")\n",
    "        self._left_fork.release()\n",
    "        print(f\"Philosopher {self.index} put down left fork\")\n",
    "    \n",
    "\n",
    "PHILOSOPHERS_COUNT = 5\n",
    "forks = [threading.Lock() for _ in range(PHILOSOPHERS_COUNT)]\n",
    "philosophers = []\n",
    "for i in range(PHILOSOPHERS_COUNT):\n",
    "    philosophers.append(\n",
    "        Philosopher(\n",
    "            index=i,\n",
    "            left_fork=forks[i],\n",
    "            right_fork=forks[(i + 1) % PHILOSOPHERS_COUNT],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def philosopher_bad(philosopher: Philosopher):\n",
    "    while True:\n",
    "        philosopher.think()\n",
    "        philosopher.pick_left_fork()\n",
    "        philosopher.pick_right_fork()\n",
    "        philosopher.eat()\n",
    "        philosopher.release_forks()\n",
    "\n",
    "\n",
    "philosopher_threads = []\n",
    "print('Main: Starting simulation')\n",
    "for philosopher in philosophers:\n",
    "    philosopher_thread = threading.Thread(target=philosopher_bad, args=(philosopher,), daemon=True)\n",
    "    philosopher_threads.append(philosopher_thread)\n",
    "    philosopher_thread.start()\n",
    "\n",
    "time.sleep(5)\n",
    "print('Main: Ending simulation')\n",
    "for philosopher_thread in philosopher_threads:\n",
    "    philosopher_thread.join(timeout=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c2931b99fa7c2",
   "metadata": {},
   "source": [
    "With the naive approach we encountered a common scenario in multithreading, called **Deadlock**. No philosopher can eat, because everyone has grabbed his left fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4fb6990aad34ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:23:22.901282Z",
     "start_time": "2025-08-25T07:23:17.389574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Good solution: always pick the lowest number fork first. Then, there will be no deadlocks.\n",
    "PHILOSOPHERS_COUNT = 5\n",
    "forks = [threading.Lock() for _ in range(PHILOSOPHERS_COUNT)]\n",
    "philosophers = []\n",
    "for i in range(PHILOSOPHERS_COUNT):\n",
    "    philosophers.append(\n",
    "        Philosopher(\n",
    "            index=i,\n",
    "            left_fork=forks[i],\n",
    "            right_fork=forks[(i + 1) % PHILOSOPHERS_COUNT],\n",
    "        )\n",
    "    )\n",
    "\n",
    "def philosopher_good(philosopher: Philosopher):\n",
    "    while True:\n",
    "        philosopher.think()\n",
    "        if philosopher.index < PHILOSOPHERS_COUNT - 1:\n",
    "            philosopher.pick_left_fork()\n",
    "            philosopher.pick_right_fork()\n",
    "        else:\n",
    "            philosopher.pick_right_fork()\n",
    "            philosopher.pick_left_fork()\n",
    "        philosopher.eat()\n",
    "        philosopher.release_forks()\n",
    "\n",
    "\n",
    "philosopher_threads = []\n",
    "print('Main: Starting simulation')\n",
    "for philosopher in philosophers:\n",
    "    philosopher_thread = threading.Thread(target=philosopher_good, args=(philosopher,), daemon=True)\n",
    "    philosopher_threads.append(philosopher_thread)\n",
    "    philosopher_thread.start()\n",
    "\n",
    "time.sleep(5)\n",
    "print('Main: Ending simulation')\n",
    "for philosopher_thread in philosopher_threads:\n",
    "    philosopher_thread.join(timeout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccba022a3b9a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:27:59.948592Z",
     "start_time": "2025-08-25T07:27:54.433001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bonus: Arbitrator solution with Semaphore: ask permission to eat\n",
    "\n",
    "PHILOSOPHERS_COUNT = 5\n",
    "forks = [threading.Lock() for _ in range(PHILOSOPHERS_COUNT)]\n",
    "arbitrator = threading.Semaphore(PHILOSOPHERS_COUNT - 1)\n",
    "philosophers = []\n",
    "for i in range(PHILOSOPHERS_COUNT):\n",
    "    philosophers.append(\n",
    "        Philosopher(\n",
    "            index=i,\n",
    "            left_fork=forks[i],\n",
    "            right_fork=forks[(i + 1) % PHILOSOPHERS_COUNT],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def philosopher_arbitrator(philosopher: Philosopher):\n",
    "    while True:\n",
    "        philosopher.think()\n",
    "        arbitrator.acquire()\n",
    "        philosopher.pick_left_fork()\n",
    "        philosopher.pick_right_fork()\n",
    "        philosopher.eat()\n",
    "        philosopher.release_forks()\n",
    "        arbitrator.release()\n",
    "\n",
    "\n",
    "philosopher_threads = []\n",
    "print('Main: Starting simulation')\n",
    "for philosopher in philosophers:\n",
    "    philosopher_thread = threading.Thread(target=philosopher_arbitrator, args=(philosopher,), daemon=True)\n",
    "    philosopher_threads.append(philosopher_thread)\n",
    "    philosopher_thread.start()\n",
    "\n",
    "time.sleep(5)\n",
    "print('Main: Ending simulation')\n",
    "for philosopher_thread in philosopher_threads:\n",
    "    philosopher_thread.join(timeout=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcf06b7a495ad6",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514c16b33b34a05",
   "metadata": {},
   "source": [
    "### Bypassing the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f78774b25af4fa",
   "metadata": {},
   "source": [
    "Problem with threads: they do not bypass GIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c9cbc8485aafb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:59:36.009130Z",
     "start_time": "2025-08-25T07:59:35.148157Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def cpu_bound_task(number):\n",
    "    return math.sqrt(number)\n",
    "\n",
    "numbers = range(5_000_000)\n",
    "start_time = time.time()\n",
    "for number in numbers:\n",
    "    cpu_bound_task(number)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Sequential execution took {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5040e5257bbd21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:02:33.332755Z",
     "start_time": "2025-08-25T08:02:32.636926Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import threading\n",
    "\n",
    "def cpu_bound_task(number):\n",
    "    return math.sqrt(number)\n",
    "\n",
    "\n",
    "def calculate_chunk(chunk):\n",
    "    for number in chunk:\n",
    "        cpu_bound_task(number)\n",
    "\n",
    "numbers = range(5_000_000)\n",
    "threads = []\n",
    "start_time = time.time()\n",
    "NUM_WORKERS = 12\n",
    "chunk_size = (len(numbers) + NUM_WORKERS - 1) // NUM_WORKERS\n",
    "chunks = [numbers[i:i + chunk_size] for i in range(0, len(numbers), chunk_size)]\n",
    "\n",
    "for chunk in chunks:\n",
    "    thread = threading.Thread(target=calculate_chunk, args=(chunk,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "print(len(threads))\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Multithreading execution took {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013808461cc590d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:02:35.709741Z",
     "start_time": "2025-08-25T08:02:35.396579Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import multiprocessing\n",
    "\n",
    "def cpu_bound_task(number):\n",
    "    return math.sqrt(number)\n",
    "\n",
    "\n",
    "def calculate_chunk(chunk):\n",
    "    for number in chunk:\n",
    "        cpu_bound_task(number)\n",
    "\n",
    "numbers = range(5_000_000)\n",
    "# threads = []\n",
    "processes = []\n",
    "start_time = time.time()\n",
    "NUM_WORKERS = 12\n",
    "chunk_size = (len(numbers) + NUM_WORKERS - 1) // NUM_WORKERS\n",
    "chunks = [numbers[i:i + chunk_size] for i in range(0, len(numbers), chunk_size)]\n",
    "\n",
    "for chunk in chunks:\n",
    "    # thread = threading.Thread(target=calculate_chunk, args=(chunk,))\n",
    "    process = multiprocessing.Process(target=calculate_chunk, args=(chunk,))\n",
    "    # threads.append(thread)\n",
    "    processes.append(process)\n",
    "    # thread.start()\n",
    "    process.start()\n",
    "\n",
    "# print(len(threads))\n",
    "# for thread in threads:\n",
    "#     thread.join()\n",
    "\n",
    "print(len(processes))\n",
    "for process in processes:\n",
    "    process.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Multiprocessing execution took {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e425ea449245524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:09:52.219191Z",
     "start_time": "2025-08-25T08:09:50.838884Z"
    }
   },
   "outputs": [],
   "source": [
    "# We don't have do the mapping ourselves: multiprocessing.Pool()\n",
    "\n",
    "import math\n",
    "import multiprocessing\n",
    "\n",
    "def cpu_bound_task(number):\n",
    "    return math.sqrt(number)\n",
    "\n",
    "numbers = range(5_000_000)\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    results = pool.map(cpu_bound_task, numbers)\n",
    "\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756d556cc41e525",
   "metadata": {},
   "source": [
    "### Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5726c73961187f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:10:38.841728Z",
     "start_time": "2025-08-25T08:10:38.838459Z"
    }
   },
   "outputs": [],
   "source": [
    "def worker_task(x):\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    result = x * x\n",
    "    return (x, result) # Return both input and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6008c965ffe7fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:11:10.447687Z",
     "start_time": "2025-08-25T08:11:10.006527Z"
    }
   },
   "outputs": [],
   "source": [
    "def example_map():\n",
    "    print(\"=== map() example ===\")\n",
    "    print(\"Processing all items, waiting for all, returning in order...\")\n",
    "    \n",
    "    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results = pool.map(worker_task, data)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print()\n",
    "\n",
    "example_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf169cd496543f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:11:56.096434Z",
     "start_time": "2025-08-25T08:11:55.673730Z"
    }
   },
   "outputs": [],
   "source": [
    "def example_map_async():\n",
    "    print(\"=== map_async() example ===\")\n",
    "    print(\"Starting processing, returning immediately, can wait for results later...\")\n",
    "    \n",
    "    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        async_result = pool.map_async(worker_task, data)\n",
    "        \n",
    "        print(\"Doing other work while processes run...\")\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        results = async_result.get()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print()\n",
    "    \n",
    "example_map_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39579af32d41dd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:13:18.131783Z",
     "start_time": "2025-08-25T08:13:17.385455Z"
    }
   },
   "outputs": [],
   "source": [
    "def example_imap():\n",
    "    print(\"=== imap() example ===\")\n",
    "    print(\"Processing items, yielding results IN ORDER as they complete...\")\n",
    "    \n",
    "    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results_iterator = pool.imap(worker_task, data)\n",
    "        \n",
    "        print(\"Results (will appear in original order, not completion order):\")\n",
    "        for i, result in enumerate(results_iterator, 1):\n",
    "            print(f\"  Received result {i}: {result}\")\n",
    "            time.sleep(0.05)  # Simulate processing results\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print()\n",
    "\n",
    "example_imap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231decb515fd6b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:16:51.367127Z",
     "start_time": "2025-08-25T08:16:50.547885Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def variable_worker_task(x):\n",
    "        sleep_time = random.uniform(0.05, 0.3)\n",
    "        time.sleep(sleep_time)\n",
    "        return (x, x * x, f\"slept {sleep_time:.3f}s\")\n",
    "\n",
    "\n",
    "def example_imap_unordered():\n",
    "    print(\"=== imap_unordered() example ===\")\n",
    "    print(\"Processing items, yielding results IN COMPLETION ORDER (fastest first)...\")\n",
    "    \n",
    "    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results_iterator = pool.imap_unordered(variable_worker_task, data)\n",
    "        \n",
    "        print(\"Results (will appear in completion order):\")\n",
    "        for i, result in enumerate(results_iterator, 1):\n",
    "            print(f\"  Received result {i}: {result}\")\n",
    "            time.sleep(0.05)  # Simulate processing results\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print()\n",
    "\n",
    "example_imap_unordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf8828d0775c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:17:36.122362Z",
     "start_time": "2025-08-25T08:17:36.116313Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== When to Use Which Method ===\")\n",
    "print()\n",
    "print(\"Use map():\")\n",
    "print(\"  - When you need ALL results before continuing\")\n",
    "print(\"  - When you need results in original order\")\n",
    "print(\"  - For simple parallel processing\")\n",
    "print()\n",
    "print(\"Use map_async():\")\n",
    "print(\"  - When you want to start processing and do other work\")\n",
    "print(\"  - When you need non-blocking execution\")\n",
    "print()\n",
    "print(\"Use imap():\")\n",
    "print(\"  - When processing LARGE datasets that don't fit in memory\")\n",
    "print(\"  - When you want to process results incrementally IN ORDER\")\n",
    "print(\"  - When you might need to stop early (break from loop)\")\n",
    "print()\n",
    "print(\"Use imap_unordered():\")\n",
    "print(\"  - When you want to process results as soon as they're ready\")\n",
    "print(\"  - When order doesn't matter\")\n",
    "print(\"  - For progress monitoring or streaming results\")\n",
    "print(\"  - Often the fastest way to process all items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98d34987ca099f",
   "metadata": {},
   "source": [
    "### Basic IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56570ffac46cbbc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:33:31.638665Z",
     "start_time": "2025-08-25T08:33:31.585461Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "data = [0]\n",
    "\n",
    "def worker():\n",
    "    data[0] += 1\n",
    "    print(f\"[child] data = {data}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"[parent before] data = {data}\")\n",
    "    p = multiprocessing.Process(target=worker)\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(f\"[parent after]  data = {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ac285e23b13f5",
   "metadata": {},
   "source": [
    "We can see that communication between processes is not as easy as with threads. In reality, the process COPIES all the variables from the parent, and later modifies those copies only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeee50b990471f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:36:21.098297Z",
     "start_time": "2025-08-25T08:36:20.812662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Queue: passing data between messages\n",
    "\n",
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def worker(q, x):\n",
    "    time.sleep(random.uniform(0.1, 0.2)) # simulate computation\n",
    "    q.put(x * x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "    xs = [1, 2, 3, 4]\n",
    "\n",
    "    procs = [multiprocessing.Process(target=worker, args=(q, x)) for x in xs]\n",
    "    for p in procs: p.start()\n",
    "    for p in procs: p.join()\n",
    "\n",
    "    results = [q.get() for _ in xs]\n",
    "    print(results) # Unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db82357057e753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:46:33.002668Z",
     "start_time": "2025-08-25T08:46:32.950699Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker(child_conn):\n",
    "    x = child_conn.recv()      # blocks until parent sends\n",
    "    child_conn.send(x + 10)    # reply\n",
    "    child_conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parent_conn, child_conn = multiprocessing.Pipe()\n",
    "\n",
    "    p = multiprocessing.Process(target=worker, args=(child_conn,))\n",
    "    p.start()\n",
    "\n",
    "    parent_conn.send(32)            # send to child\n",
    "    reply = parent_conn.recv()      # receive from child\n",
    "    print(reply)\n",
    "\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebab48944956f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T08:43:03.828930Z",
     "start_time": "2025-08-25T08:42:52.128025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deadlocks: here we go again\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def child(q_c2p, q_p2c):\n",
    "    print('CHILD START')\n",
    "    q_c2p.put(\"child: hello\")     # succeeds (queue was empty)\n",
    "    time.sleep(0.1)\n",
    "    q_p2c.put(\"child: follow-up\") # <-- blocks forever if parent has filled q_p2c\n",
    "    print('CHILD FINISH')\n",
    "\n",
    "q_p2c = multiprocessing.Queue(maxsize=1)   # parent -> child\n",
    "q_c2p = multiprocessing.Queue(maxsize=1)   # child  -> parent\n",
    "\n",
    "p = multiprocessing.Process(target=child, args=(q_c2p, q_p2c))\n",
    "p.start()\n",
    "\n",
    "print('PARENT START')\n",
    "q_p2c.put(\"parent: hello\")     # succeeds (queue was empty)\n",
    "time.sleep(0.1)\n",
    "q_c2p.put(\"parent: follow-up\") # <-- blocks forever; child is also blocked above\n",
    "\n",
    "print('PARENT FINISH')\n",
    "print(q_c2p.get())\n",
    "print(q_p2c.get())\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63928e87f14f184c",
   "metadata": {},
   "source": [
    "## Concurrency: Parallelizing Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28371d9ec0e2491b",
   "metadata": {},
   "source": [
    "Now let's talk about parallelization in general and libraries to do that. As a toy example, we will be using (again) taking square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15d39dc325e0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:33:42.097025Z",
     "start_time": "2025-08-25T10:33:42.086664Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import math\n",
    "import multiprocessing\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def worker_task(number: int):\n",
    "    for i in range(1000):\n",
    "        if number % 2 == 0:\n",
    "            number = number // 2\n",
    "        else:\n",
    "            number = 3 * number + 1\n",
    "    return number\n",
    "\n",
    "\n",
    "START_NUM = 1\n",
    "END_NUM = 50000 + 1\n",
    "num_to_index = lambda num: num - 1\n",
    "index_to_num = lambda idx: idx + 1\n",
    "\n",
    "\n",
    "def naive_implementation():\n",
    "    results = [0 for i in range(START_NUM, END_NUM)]\n",
    "    for i, num in enumerate(range(START_NUM, END_NUM)):\n",
    "        results[i] = worker_task(num)\n",
    "    return results\n",
    "\n",
    "\n",
    "def threading_implementation(max_workers=4):\n",
    "    results = [0 for i in range(START_NUM, END_NUM)]\n",
    "    threads = []\n",
    "    numbers_per_thread = math.ceil(len(results) / max_workers)\n",
    "    \n",
    "    def thread_worker(start_idx, end_idx):\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            results[idx] = worker_task(index_to_num(idx))\n",
    "    \n",
    "    for i in range(max_workers):\n",
    "        start_idx = i * numbers_per_thread\n",
    "        end_idx = min(start_idx + numbers_per_thread, len(results))\n",
    "        thread = threading.Thread(target=thread_worker, args=(start_idx, end_idx))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    return results\n",
    "\n",
    "\n",
    "def multiprocessing_implementation(max_workers=4):\n",
    "    results = [0 for i in range(START_NUM, END_NUM)]\n",
    "    processes = []\n",
    "    numbers_per_thread = math.ceil(len(results) / max_workers)\n",
    "    result_queue = multiprocessing.Queue()\n",
    "    \n",
    "    def process_worker(start_idx, end_idx):\n",
    "        batch_results = []\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            batch_results.append((idx, worker_task(index_to_num(idx))))\n",
    "        result_queue.put(batch_results)\n",
    "    \n",
    "    for i in range(max_workers):\n",
    "        start_idx = i * numbers_per_thread\n",
    "        end_idx = min(start_idx + numbers_per_thread, len(results))\n",
    "        process = multiprocessing.Process(target=process_worker, args=(start_idx, end_idx))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "    \n",
    "    for _ in range(max_workers):\n",
    "        batch_results = result_queue.get()\n",
    "        for idx, result in batch_results:\n",
    "            results[idx] = result\n",
    "    \n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    return results\n",
    "\n",
    "\n",
    "def threadpool_implementation(max_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(worker_task, range(START_NUM, END_NUM)))\n",
    "    return results\n",
    "\n",
    "\n",
    "def processpool_implementation(max_workers=4):\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(worker_task, range(START_NUM, END_NUM), chunksize=1000))\n",
    "    return results\n",
    "\n",
    "\n",
    "def joblib_threading_implementation(n_jobs=4):\n",
    "    results = joblib.Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "        joblib.delayed(worker_task)(i) for i in range(START_NUM, END_NUM)\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "def joblib_multiprocessing_implementation(n_jobs=4):\n",
    "    results = joblib.Parallel(n_jobs=n_jobs, backend='multiprocessing')(\n",
    "        joblib.delayed(worker_task)(i) for i in range(START_NUM, END_NUM)\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "def joblib_loky_implementation(n_jobs=4):\n",
    "    results = joblib.Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "        joblib.delayed(worker_task)(i) for i in range(START_NUM, END_NUM)\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46e135437fce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:34:32.891588Z",
     "start_time": "2025-08-25T10:33:45.486995Z"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark_implementation(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    results = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, results\n",
    "\n",
    "implementations = [\n",
    "    (\"Naive Sequential\", naive_implementation),\n",
    "    (\"Threading (4 threads)\", lambda: threading_implementation(4)),\n",
    "    (\"Threading (12 threads)\", lambda: threading_implementation(12)),\n",
    "    (\"Threading (100 threads)\", lambda: threading_implementation(100)),\n",
    "    (\"Multiprocessing (4 proc)\", lambda: multiprocessing_implementation(4)),\n",
    "    (\"Multiprocessing (12 proc)\", lambda: multiprocessing_implementation(12)),\n",
    "    (\"ThreadPool (4 workers)\", lambda: threadpool_implementation(4)),\n",
    "    (\"ThreadPool (12 workers)\", lambda: threadpool_implementation(12)),\n",
    "    (\"ThreadPool (100 workers)\", lambda: threadpool_implementation(100)),\n",
    "    (\"ProcessPool (4 workers)\", lambda: processpool_implementation(4)),\n",
    "    (\"ProcessPool (12 workers)\", lambda: processpool_implementation(12)),\n",
    "    (\"Joblib Threading (4)\", lambda: joblib_threading_implementation(4)),\n",
    "    (\"Joblib Threading (12)\", lambda: joblib_threading_implementation(12)),\n",
    "    (\"Joblib Threading (100)\", lambda: joblib_threading_implementation(100)),\n",
    "    (\"Joblib Multiprocessing (4)\", lambda: joblib_multiprocessing_implementation(4)),\n",
    "    (\"Joblib Multiprocessing (12)\", lambda: joblib_multiprocessing_implementation(12)),\n",
    "    (\"Joblib Loky (4)\", lambda: joblib_loky_implementation(4)),\n",
    "    (\"Joblib Loky (12)\", lambda: joblib_loky_implementation(12)),\n",
    "]\n",
    "\n",
    "print(\"Benchmarking parallelization approaches (4 workers/threads):\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "_, reference_result = benchmark_implementation(naive_implementation)\n",
    "\n",
    "results = []\n",
    "for name, func in implementations:\n",
    "    try:\n",
    "        execution_time, result = benchmark_implementation(func)\n",
    "        \n",
    "        # Verify results match\n",
    "        is_correct = all(\n",
    "            ref == comp for ref, comp in zip(reference_result, result)\n",
    "        )\n",
    "        status = \"✓\" if is_correct else \"✗\"\n",
    "        \n",
    "        results.append((name, execution_time, status))\n",
    "        print(f\"{name:25s}: {execution_time:6.3f} seconds {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append((name, float('inf'), f\"Error: {str(e)}\"))\n",
    "        print(f\"{name:25s}: FAILED - {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197ad8bc1896fdb",
   "metadata": {},
   "source": [
    "## Exercise: Mandelbrot Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50f604865ad33d",
   "metadata": {},
   "source": [
    "In this task, the goal is to create a Mandelbrot set. The simple implementation is given below. Now, we need to think how to parallelize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:45:57.152698Z",
     "start_time": "2025-08-25T10:45:57.145318Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_mandelbrot_image_simple(\n",
    "        x_min: float,\n",
    "        x_max: float,\n",
    "        y_min: float,\n",
    "        y_max: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        max_iter: int = 200\n",
    "):\n",
    "    x_step = (x_max - x_min) / width\n",
    "    y_step = (y_max - y_min) / height\n",
    "    \n",
    "    C = [[0 for x in range(width)] for y in range(height)]\n",
    "    Z = [[0 for x in range(width)] for y in range(height)]\n",
    "    active = [[True for x in range(width)] for y in range(height)]\n",
    "    escape_iter = [[max_iter for x in range(width)] for y in range(height)]\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            C[i][j] = (x_min + j * x_step) + 1j * (y_min + i * y_step)\n",
    "    \n",
    "    for iter_num in range(max_iter):\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if active[i][j]:\n",
    "                    Z[i][j] = Z[i][j] * Z[i][j] + C[i][j]\n",
    "                    if abs(Z[i][j]) > 2:\n",
    "                        escape_iter[i][j] = iter_num\n",
    "                        active[i][j] = False\n",
    "    return escape_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac9424a9f0e1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:46:16.448905Z",
     "start_time": "2025-08-25T10:46:16.094367Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def visualize(\n",
    "        fn, \n",
    "        width=400,\n",
    "        height=400,\n",
    "        xmin=-2.5,\n",
    "        xmax=1.0,\n",
    "        y_center=0.0,\n",
    "        **kwargs\n",
    "):\n",
    "    y_span = (xmax - xmin) * (height / width) / 2.0\n",
    "    ymin, ymax = y_center - y_span, y_center + y_span\n",
    "    \n",
    "    time_start = time.time()\n",
    "    img = fn(xmin, xmax, ymin, ymax, width, height, max_iter=250, **kwargs)\n",
    "    print(f\"Time: {time.time() - time_start:.3f} s\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, extent=(xmin, xmax, ymin, ymax), origin=\"lower\", cmap=\"turbo\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406577a713e3abb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:46:20.333990Z",
     "start_time": "2025-08-25T10:46:17.836485Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(create_mandelbrot_image_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d86b82a4a5957",
   "metadata": {},
   "source": [
    "We can notice that each pixel is generated independently. That gives us opportunity for parallelization. Let's perform multiprocessing by vertical coordinate (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bb0f672b3254e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:48:53.660298Z",
     "start_time": "2025-08-25T10:48:53.655117Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def create_mandelbrot_image_multiprocess(\n",
    "        x_min: float,\n",
    "        x_max: float,\n",
    "        y_min: float,\n",
    "        y_max: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        max_iter: int = 200,\n",
    "        num_workers: int = 4\n",
    "):\n",
    "    chunk_size = height // num_workers\n",
    "    y_step = (y_max - y_min) / height\n",
    "    \n",
    "    chunks = [\n",
    "        (\n",
    "            x_min,\n",
    "            x_max,\n",
    "            y_min + i * y_step, \n",
    "            y_min + (i + chunk_size) * y_step,\n",
    "            width,\n",
    "            chunk_size,\n",
    "            max_iter\n",
    "        )\n",
    "        for i in range(0, height, chunk_size)\n",
    "    ]\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        sub_images = pool.starmap(create_mandelbrot_image_simple, chunks)\n",
    "    \n",
    "    result = []\n",
    "    for sub_image in sub_images:\n",
    "        result += sub_image\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ae5ffb7f05c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:48:54.915500Z",
     "start_time": "2025-08-25T10:48:53.782022Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(create_mandelbrot_image_multiprocess, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84a22833b9bfc8",
   "metadata": {},
   "source": [
    "When working with arrays, it's too hard to parallelize everything by hand. Furthermore, python lists are not memory-efficient, so we might lose time on creating and modifying them. That's why usually numpy is used for working with arrays. You will learn it in more details later, but now you can check how it speeds up processing significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a4cdf68d373c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:52:06.587940Z",
     "start_time": "2025-08-25T10:52:06.583804Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_mandelbrot_image_numpy(\n",
    "        x_min: float,\n",
    "        x_max: float,\n",
    "        y_min: float,\n",
    "        y_max: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        max_iter: int = 200\n",
    "):\n",
    "    \n",
    "    # C = [[0 for x in range(width)] for y in range(height)]\n",
    "    # for i in range(height):\n",
    "    #     for j in range(width):\n",
    "    #         C[i][j] = (x_min + j * x_step) + 1j * (y_min + i * y_step)\n",
    "    x_range = np.linspace(x_min, x_max, width)\n",
    "    y_range = np.linspace(y_min, y_max, height)\n",
    "    C = x_range + 1j * y_range[:, None]\n",
    "    \n",
    "    # Z = [[0 for x in range(width)] for y in range(height)]\n",
    "    Z = np.zeros_like(C)\n",
    "    \n",
    "    # active = [[True for x in range(width)] for y in range(height)]\n",
    "    active = np.full_like(Z, fill_value=True, dtype=bool)\n",
    "    \n",
    "    # escape_iter = [[max_iter for x in range(width)] for y in range(height)]    \n",
    "    escape_iter = np.full_like(C, fill_value=max_iter, dtype=np.uint16)\n",
    "    \n",
    "    for iter_num in range(max_iter):\n",
    "        # for i in range(height):\n",
    "        #     for j in range(width):\n",
    "        #         if active[i][j]:\n",
    "        #             Z[i][j] = Z[i][j] * Z[i][j] + C[i][j]\n",
    "        #             if abs(Z[i][j]) > 2:\n",
    "        #                 escape_iter[i][j] = iter_num\n",
    "        #                 active[i][j] = False\n",
    "        Z[active] = Z[active] * Z[active] + C[active]\n",
    "        escape_mask = np.abs(Z) > 2\n",
    "        escape_iter[escape_mask & active] = iter_num\n",
    "        active[escape_mask] = False\n",
    "        active = ~escape_mask\n",
    "    \n",
    "    return escape_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125da4bea204ecac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:52:08.207415Z",
     "start_time": "2025-08-25T10:52:07.314590Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(create_mandelbrot_image_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42647a75d4f4df",
   "metadata": {},
   "source": [
    "Now, let's combine numpy with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428eb1e13ad4f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:53:09.773035Z",
     "start_time": "2025-08-25T10:53:09.769694Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_mandelbrot_image_numpy_multiprocess(\n",
    "        x_min: float,\n",
    "        x_max: float,\n",
    "        y_min: float,\n",
    "        y_max: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        max_iter: int = 200,\n",
    "        num_workers: int = 4\n",
    "):\n",
    "    chunk_size = height // num_workers\n",
    "    y_step = (y_max - y_min) / height\n",
    "    \n",
    "    chunks = [\n",
    "        (\n",
    "            x_min,\n",
    "            x_max,\n",
    "            y_min + i * y_step, \n",
    "            y_min + (i + chunk_size) * y_step,\n",
    "            width,\n",
    "            chunk_size,\n",
    "            max_iter\n",
    "        )\n",
    "        for i in range(0, height, chunk_size)\n",
    "    ]\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        sub_images = pool.starmap(create_mandelbrot_image_numpy, chunks)\n",
    "    \n",
    "    return np.vstack(sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27cd3f991944b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:53:35.406158Z",
     "start_time": "2025-08-25T10:53:35.065558Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(create_mandelbrot_image_numpy_multiprocess, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6aea592e952ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:54:28.803416Z",
     "start_time": "2025-08-25T10:54:27.631470Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(create_mandelbrot_image_numpy_multiprocess, num_workers=12, width=1280, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb715a906b72d6",
   "metadata": {},
   "source": [
    "For heavy mathematical tasks, usually the best choice is compiling your code with numba. This makes it a lot faster, even than numpy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d3d9798a4675c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:55:37.244416Z",
     "start_time": "2025-08-25T10:55:36.895926Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit, prange\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def create_mandelbrot_image_numba(\n",
    "        x_min: float,\n",
    "        x_max: float,\n",
    "        y_min: float,\n",
    "        y_max: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        max_iter: int = 200\n",
    "):\n",
    "    result = np.empty((height, width), np.uint16)\n",
    "    dx = (x_max - x_min) / width\n",
    "    dy = (y_max - y_min) / height\n",
    "\n",
    "    for i in prange(height):\n",
    "        y = y_min + i * dy\n",
    "        row = result[i]\n",
    "        for j in range(width):\n",
    "            x = x_min + j * dx\n",
    "\n",
    "            zx = 0.0\n",
    "            zy = 0.0\n",
    "            iter_num = 0\n",
    "            while (zx*zx + zy*zy) <= 4.0 and iter_num < max_iter:\n",
    "                zx_new  = zx*zx - zy*zy + x\n",
    "                zy  = 2.0*zx*zy + y\n",
    "                zx = zx_new\n",
    "                iter_num += 1\n",
    "\n",
    "            row[j] = iter_num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496986a9dd3028f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:56:03.118634Z",
     "start_time": "2025-08-25T10:56:01.547410Z"
    }
   },
   "outputs": [],
   "source": [
    "# First compile is slow: that's how JIT works\n",
    "visualize(create_mandelbrot_image_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac48ac7d3ca1441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T10:56:18.198240Z",
     "start_time": "2025-08-25T10:56:18.094122Z"
    }
   },
   "outputs": [],
   "source": [
    "# But now it's blazingly fast!!!\n",
    "visualize(create_mandelbrot_image_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07f57d05c0e9d6",
   "metadata": {},
   "source": [
    "Now, let's create a zooming video in the set. Remember, that we need to be memory-efficient as frames take a lot of memory. That's why, we'll use Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156aeebd6cada83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:29:56.555419Z",
     "start_time": "2025-08-25T11:29:56.550600Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_mandelbrot_video_frames(\n",
    "        x_min_start: float,\n",
    "        x_max_start: float,\n",
    "        y_min_start: float,\n",
    "        y_max_start: float,\n",
    "        target_x: float,\n",
    "        target_y: float,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        num_frames: int,\n",
    "        zoom_factor_per_frame: float,\n",
    "        max_iter: int = 200\n",
    ") -> Generator[np.ndarray, None, None]:\n",
    "    x_min, x_max, y_min, y_max = x_min_start, x_max_start, y_min_start, y_max_start\n",
    "    for frame_num in tqdm(range(num_frames)):\n",
    "        frame = create_mandelbrot_image_numba(\n",
    "            x_min=x_min,\n",
    "            x_max=x_max,\n",
    "            y_min=y_min,\n",
    "            y_max=y_max,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            max_iter=max_iter\n",
    "        )\n",
    "        \n",
    "        yield frame\n",
    "\n",
    "        current_center_x = (x_min + x_max) / 2\n",
    "        current_center_y = (y_min + y_max) / 2\n",
    "\n",
    "        current_width = x_max - x_min\n",
    "        current_height = y_max - y_min\n",
    "\n",
    "        new_width = current_width / zoom_factor_per_frame\n",
    "        new_height = current_height / zoom_factor_per_frame\n",
    "\n",
    "        zoom_center_weight = 0.1\n",
    "        new_center_x = current_center_x * (1 - zoom_center_weight) + target_x * zoom_center_weight\n",
    "        new_center_y = current_center_y * (1 - zoom_center_weight) + target_y * zoom_center_weight\n",
    "\n",
    "        x_min = new_center_x - new_width / 2\n",
    "        x_max = new_center_x + new_width / 2\n",
    "        y_min = new_center_y - new_height / 2\n",
    "        y_max = new_center_y + new_height / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ac1b8f300671e",
   "metadata": {},
   "source": [
    "Now, we create imageio VideoWriter context class for convenient video saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5404d99bc6a59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:02:27.424504Z",
     "start_time": "2025-08-25T11:02:27.387762Z"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VideoWriter:\n",
    "    output_path: str\n",
    "    fps: float = 30\n",
    "    codec: str = 'libx264'\n",
    "    pix_fmt: str = 'yuv420p'\n",
    "    _writer: imageio.core.format.Format.Writer | None = field(default=None, init=False, repr=False)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._writer = imageio.get_writer(\n",
    "            self.output_path,\n",
    "            format=\"FFMPEG\",\n",
    "            fps=self.fps,\n",
    "            codec=self.codec,\n",
    "            pixelformat=self.pix_fmt\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self._writer is not None:\n",
    "            self._writer.close()\n",
    "            self._writer = None\n",
    "    \n",
    "    \n",
    "    def add(self, frame: np.ndarray) -> None:\n",
    "        if self._writer is None:\n",
    "            raise RuntimeError(\"Must be used as context manager\")\n",
    "        \n",
    "        frame = np.asarray(frame)\n",
    "        if frame.ndim != 3 or frame.shape[2] != 3:\n",
    "            raise ValueError(f\"Unsupported frame shape: {frame.shape}\")\n",
    "        \n",
    "        self._writer.append_data(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9cc7c00f58d92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:05:39.395367Z",
     "start_time": "2025-08-25T11:05:39.391526Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "turbo_cmap = plt.colormaps['turbo']\n",
    "def transform_frame(frame: np.ndarray, max_iter: int, scale_down: int | None = None):\n",
    "    frame = np.asarray(frame)\n",
    "    normalized = np.clip(frame.astype(np.float32) / max_iter, 0, 1)\n",
    "    colored_frame = turbo_cmap(normalized)\n",
    "    colored_frame_uint8 = (colored_frame[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    if scale_down is not None and scale_down > 1:\n",
    "        h, w = colored_frame_uint8.shape[:2]\n",
    "        colored_frame_uint8 = np.array(\n",
    "            Image.fromarray(colored_frame_uint8).resize((w // scale_down, h // scale_down), resample=Image.LANCZOS)\n",
    "        )\n",
    "    \n",
    "    return colored_frame_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fe1a1652ba737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:13:05.861507Z",
     "start_time": "2025-08-25T11:08:30.316473Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_view = (-2.0, 0.8, -1.25, 1.25) # x_min, x_max, y_min, y_max\n",
    "target_point = (-0.743653884279361, 0.131822903750375)  # A interesting point near the \"seahorse valley\"\n",
    "resolution = (640, 480)\n",
    "video_length_frames = 800\n",
    "zoom_per_frame = 1.04\n",
    "fps = 30\n",
    "max_iterations = 400\n",
    "scale_down = 3\n",
    "\n",
    "with VideoWriter(\"mandelbrot_zoom.mp4\", fps=fps) as writer:\n",
    "    for frame in generate_mandelbrot_video_frames(\n",
    "        x_min_start=initial_view[0],\n",
    "        x_max_start=initial_view[1],\n",
    "        y_min_start=initial_view[2],\n",
    "        y_max_start=initial_view[3],\n",
    "        target_x=target_point[0],\n",
    "        target_y=target_point[1],\n",
    "        width=resolution[0] * scale_down,\n",
    "        height=resolution[1] * scale_down,\n",
    "        num_frames=video_length_frames,\n",
    "        zoom_factor_per_frame=zoom_per_frame,\n",
    "        max_iter=max_iterations\n",
    "    ):\n",
    "        transformed_frame = transform_frame(frame, max_iterations, scale_down=scale_down)\n",
    "        writer.add(transformed_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36919763d6efbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:30:30.182819Z",
     "start_time": "2025-08-25T11:30:30.180607Z"
    }
   },
   "outputs": [],
   "source": [
    "# from ipywidgets import Video\n",
    "# \n",
    "# Video.from_file(\"mandelbrot_zoom.mp4\", width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b137e3afa0945e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onerec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
